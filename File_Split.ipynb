{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RintaroFujita/google-colab/blob/main/File_Split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "dihVXtEL_Rax",
        "outputId": "e6ed9d91-e992-40bc-b898-c10d1eae176d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhtBVqdd--Cq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "source_dir = '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise'\n",
        "split_dir = [\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_11',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_12',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_13',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_14',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_15',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_16',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_17',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_18',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_19',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise/Line_20'\n",
        "]\n",
        "\n",
        "\n",
        "for dir in split_dir:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "image_files = [f for f in os.listdir(source_dir) if f.endswith(('.png', '.jpg', '.jpeg','.JPG'))]\n",
        "\n",
        "num_dirs = len(split_dir)\n",
        "\n",
        "for i, image_file in enumerate(image_files):\n",
        "    src_path = os.path.join(source_dir, image_file)\n",
        "\n",
        "    dest_dir = split_dir[i % num_dirs]\n",
        "    dest_path = os.path.join(dest_dir, image_file)\n",
        "    shutil.move(src_path, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6OaWqXTbM-o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_dir = '/content/drive/MyDrive/I2T Recognition Dataset/ships_images'\n",
        "destination_dirs = [\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/ships_images/1',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/ships_images/2',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/ships_images/3',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/ships_images/4',\n",
        "    '/content/drive/MyDrive/I2T Recognition Dataset/ships_images/5'\n",
        "]\n",
        "\n",
        "for dir in destination_dirs:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "image_files = os.listdir(source_dir)\n",
        "\n",
        "dir_num = 0\n",
        "\n",
        "for image_file in image_files:\n",
        "    if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "        src_path = os.path.join(source_dir, image_file)\n",
        "        dest_dir = destination_dirs[dir_num]\n",
        "        dest_path = os.path.join(dest_dir, image_file)\n",
        "        shutil.move(src_path, dest_path)\n",
        "        dir_index += 1\n",
        "        if dir_num >= len(destination_dirs):\n",
        "            dir_num = 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvhCRy8FRo6D"
      },
      "source": [
        "画像スクレイピング"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U29vmRJWRoe1"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリをインストール\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install -y chromium-chromedriver\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from PIL import Image\n",
        "import os\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from google.colab import drive\n",
        "\n",
        "# Googleドライブをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def scrape_images(query, num_images=100):\n",
        "    # 画像を保存するディレクトリ\n",
        "    save_dir = f\"/content/drive/MyDrive/I2T Recognition Dataset/Web_Scraping/{query.replace(' ', '_')}\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    # 取得するURL\n",
        "    URL = f\"https://www.google.com/search?hl=en&tbm=isch&q={query.replace(' ', '+')}\"\n",
        "\n",
        "    # Chromeドライバのオプションを設定\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')  # ヘッドレスモードを有効にする\n",
        "    options.add_argument('--no-sandbox')  # サンドボックスモードを無効にする\n",
        "    options.add_argument('--disable-dev-shm-usage')  # /dev/shmパーティションの使用を無効にする\n",
        "\n",
        "    # WebDriverを設定\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    # URLを取得し、ページ情報を抽出\n",
        "    driver.get(URL)\n",
        "    driver.implicitly_wait(10)  # 暗黙の待機\n",
        "\n",
        "    # 画像をスクレイピングするための要素を取得\n",
        "    results = driver.find_elements(By.TAG_NAME, \"img\")  # imgタグを取得\n",
        "\n",
        "    # 画像の保存処理\n",
        "    saved_images = 0\n",
        "    for img in results:\n",
        "        try:\n",
        "            img_url = img.get_attribute(\"src\")\n",
        "            if img_url and img_url.startswith('http'):  # 有効なURLのみ処理\n",
        "                img_response = requests.get(img_url)\n",
        "\n",
        "                # 画像の内容を確認\n",
        "                if 'image' in img_response.headers['Content-Type']:\n",
        "                    img_data = Image.open(BytesIO(img_response.content))\n",
        "\n",
        "                    # 画像を128x128にリサイズ\n",
        "                    img_data = img_data.resize((128, 128))\n",
        "\n",
        "                    # 画像を保存\n",
        "                    img_data.save(os.path.join(save_dir, f'image_{saved_images + 1}.png'))\n",
        "                    print(f\"画像 {saved_images + 1} を保存しました\")\n",
        "                    saved_images += 1\n",
        "\n",
        "                    if saved_images >= num_images:  # 取得する画像数を制限\n",
        "                        break\n",
        "                else:\n",
        "                    print(f\"無効な画像URL: {img_url}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"画像の保存中にエラーが発生しました: {e}\")\n",
        "\n",
        "\n",
        "    driver.quit()\n",
        "\n",
        "# 画像をスクレイピングする関数を実行\n",
        "scrape_images('cats', num_images=100)  # 'cats'を検索\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBToACeG617B"
      },
      "source": [
        "file dupricate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8fSspu963kB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Google Driveをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ディレクトリのパスを指定\n",
        "dir1 = '/content/drive/MyDrive/I2T Recognition Dataset'\n",
        "dir2 = '/content/drive/MyDrive/I2T Recognition Dataset/SwiftTextRecognitoin_MisrecognizeDataset-main'\n",
        "output_dir = '/content/drive/MyDrive/I2T Recognition Dataset/Original_Data'\n",
        "\n",
        "# 出力用のディレクトリを作成 (存在しない場合)\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# ディレクトリ1内のファイル名を再帰的に取得 (ファイル名のみを取得)\n",
        "files_dir1 = {}\n",
        "for root, dirs, files in os.walk(dir1):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG')):\n",
        "            rel_dir = os.path.relpath(root, dir1)  # 相対ディレクトリパスを取得\n",
        "            files_dir1[file] = rel_dir  # ファイル名とその親ディレクトリの相対パスを保存\n",
        "\n",
        "# ディレクトリ2内のファイル名を再帰的に取得 (ファイル名のみを取得)\n",
        "files_dir2 = set()\n",
        "for root, dirs, files in os.walk(dir2):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG')):\n",
        "            files_dir2.add(file)  # ファイル名のみをセットに追加\n",
        "\n",
        "# 両方のディレクトリに含まれるファイル名を取得\n",
        "common_images = set(files_dir1.keys()).intersection(files_dir2)\n",
        "\n",
        "# 共通の画像ファイルをディレクトリ1内のサブディレクトリにコピー\n",
        "for image in common_images:\n",
        "    # ディレクトリ1の相対パスからコピー元のパスを作成\n",
        "    src_dir = os.path.join(dir1, files_dir1[image])\n",
        "    src = os.path.join(src_dir, image)\n",
        "\n",
        "    # コピー先のディレクトリパスを作成（元のディレクトリ構造を保持）\n",
        "    dst_dir = os.path.join(output_dir, files_dir1[image])\n",
        "    if not os.path.exists(dst_dir):\n",
        "        os.makedirs(dst_dir)  # 必要に応じてサブディレクトリを作成\n",
        "\n",
        "    dst = os.path.join(dst_dir, image)  # サブディレクトリ内の保存パス\n",
        "    shutil.copy(src, dst)  # ファイルをコピー\n",
        "    print(f'Copied: {image} to {dst_dir}')\n",
        "\n",
        "print(f'Total {len(common_images)} images copied to {output_dir}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SAQixNYmWF5"
      },
      "source": [
        "共通ファイルコピー"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe4ODaVomYYi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "subdir_name = 'City'\n",
        "\n",
        "\n",
        "dir1 = '/content/drive/MyDrive/I2T Recognition Dataset/Aerial_Landscapes/Mountain'\n",
        "dir2 = '/content/drive/MyDrive/I2T Recognition Dataset/SwiftTextRecognitoin_MisrecognizeDataset-main/City'\n",
        "output_dir = '/content/drive/MyDrive/I2T Recognition Compare /Compare'\n",
        "\n",
        "\n",
        "original_dir = os.path.join(output_dir, 'Original', subdir_name)\n",
        "recognition_dir = os.path.join(output_dir, 'Recognition', subdir_name)\n",
        "\n",
        "if not os.path.exists(original_dir):\n",
        "    os.makedirs(original_dir)\n",
        "if not os.path.exists(recognition_dir):\n",
        "    os.makedirs(recognition_dir)\n",
        "\n",
        "files_dir1 = {}\n",
        "for root, dirs, files in os.walk(dir1):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG')):\n",
        "            rel_dir = os.path.relpath(root, dir1)\n",
        "            files_dir1[file] = rel_dir\n",
        "\n",
        "files_dir2 = {}\n",
        "for root, dirs, files in os.walk(dir2):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG')):\n",
        "            rel_dir = os.path.relpath(root, dir2)\n",
        "            files_dir2[file] = rel_dir\n",
        "\n",
        "common_images = set()\n",
        "for file1 in files_dir1.keys():\n",
        "    for file2 in files_dir2.keys():\n",
        "        if file1 in file2 or file2 in file1:\n",
        "            common_images.add(file1)\n",
        "            common_images.add(file2)\n",
        "\n",
        "for image in common_images:\n",
        "    if image in files_dir1:\n",
        "        src_dir1 = os.path.join(dir1, files_dir1[image])\n",
        "        src1 = os.path.join(src_dir1, image)\n",
        "        dst_dir1 = os.path.join(original_dir, files_dir1[image])\n",
        "        if not os.path.exists(dst_dir1):\n",
        "            os.makedirs(dst_dir1)\n",
        "        dst1 = os.path.join(dst_dir1, image)\n",
        "        shutil.copy(src1, dst1)\n",
        "        print(f'Copied from Dir1: {image} to {dst_dir1}')\n",
        "\n",
        "    if image in files_dir2:\n",
        "        src_dir2 = os.path.join(dir2, files_dir2[image])\n",
        "        src2 = os.path.join(src_dir2, image)\n",
        "        dst_dir2 = os.path.join(recognition_dir, files_dir2[image])\n",
        "        if not os.path.exists(dst_dir2):\n",
        "            os.makedirs(dst_dir2)\n",
        "        dst2 = os.path.join(dst_dir2, image)\n",
        "        shutil.copy(src2, dst2)\n",
        "        print(f'Copied from Dir2: {image} to {dst_dir2}')\n",
        "\n",
        "print(f'Total {len(common_images)} images copied to {output_dir}.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7NK_ez4vblp"
      },
      "source": [
        "Line draw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCB6QAx2vcnq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "save_directory = '/content/drive/MyDrive/I2T Recognition Dataset/Line'  # 必要に応じてパスを変更\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "def generate_and_save_image():\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "\n",
        "    points = np.random.rand(10, 2) * 400\n",
        "\n",
        "    for i in range(len(points) - 1):\n",
        "        p1 = points[i]\n",
        "        p2 = points[i + 1]\n",
        "\n",
        "\n",
        "        cp1 = p1 + np.random.rand(2) * 100 - 50\n",
        "        cp2 = p2 + np.random.rand(2) * 100 - 50\n",
        "\n",
        "\n",
        "        t = np.linspace(0, 1, 100)\n",
        "        curve_x = (1 - t)**3 * p1[0] + \\\n",
        "                   3 * (1 - t)**2 * t * cp1[0] + \\\n",
        "                   3 * (1 - t) * t**2 * cp2[0] + \\\n",
        "                   t**3 * p2[0]\n",
        "\n",
        "        curve_y = (1 - t)**3 * p1[1] + \\\n",
        "                   3 * (1 - t)**2 * t * cp1[1] + \\\n",
        "                   3 * (1 - t) * t**2 * cp2[1] + \\\n",
        "                   t**3 * p2[1]\n",
        "\n",
        "        plt.plot(curve_x, curve_y, color='black', lw=5)\n",
        "\n",
        "    unique_id = uuid.uuid4()\n",
        "    file_name = f'image_{unique_id}.jpg'\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_directory, file_name), bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "for _ in range(9300):\n",
        "    generate_and_save_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5J9Dkq0fyVP"
      },
      "source": [
        "2d noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x23Poa1QgnQP"
      },
      "outputs": [],
      "source": [
        "!pip install noise\n",
        "import os\n",
        "import uuid\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from noise import pnoise1\n",
        "import random\n",
        "\n",
        "save_directory = '/content/drive/MyDrive/I2T Recognition Dataset/2dnoise'\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "width, height = 200, 200\n",
        "\n",
        "def generate_noise(t, offset, seed):\n",
        "    return pnoise1(t + offset + seed, repeat=1024)\n",
        "\n",
        "def generate_and_save_image(t=0):\n",
        "    random_seed = random.uniform(0, 1000)\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.xlim(0, width)\n",
        "    plt.ylim(0, height)\n",
        "    plt.axis('off')\n",
        "\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    scale_factor = 0.65\n",
        "    for _ in range(100):\n",
        "        x1, y1 = center_x + width * scale_factor * (generate_noise(t, 15, random_seed) - 0.5), center_y + height * scale_factor * (generate_noise(t, 55, random_seed) - 0.5)\n",
        "        x2, y2 = center_x + width * scale_factor * (generate_noise(t, 25, random_seed) - 0.5), center_y + height * scale_factor * (generate_noise(t, 65, random_seed) - 0.5)\n",
        "        x3, y3 = center_x + width * scale_factor * (generate_noise(t, 35, random_seed) - 0.5), center_y + height * scale_factor * (generate_noise(t, 75, random_seed) - 0.5)\n",
        "        x4, y4 = center_x + width * scale_factor * (generate_noise(t, 45, random_seed) - 0.5), center_y + height * scale_factor * (generate_noise(t, 85, random_seed) - 0.5)\n",
        "\n",
        "        bezier_points = np.array([\n",
        "            [x1, y1],\n",
        "            [x2, y2],\n",
        "            [x3, y3],\n",
        "            [x4, y4]\n",
        "        ])\n",
        "\n",
        "        plt.plot(bezier_points[:, 0], bezier_points[:, 1], 'k-', alpha=0.07)\n",
        "        t += 0.005\n",
        "    unique_id = uuid.uuid4()\n",
        "    file_name = f'image_{unique_id}.jpg'\n",
        "    plt.savefig(os.path.join(save_directory, file_name), bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "for _ in range(9300):\n",
        "    generate_and_save_image()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e66ItPYAAukd"
      },
      "source": [
        "smile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K8DIhEuzsZY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import uuid\n",
        "import matplotlib.pyplot as plt\n",
        "import dlib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# モデル保存ディレクトリ\n",
        "model_path = '/content/drive/MyDrive/SmileModel/smile_model.pth'\n",
        "predictor_path = \"/content/drive/MyDrive/shape_predictor_68_face_landmarks.dat\"  # 必要に応じてパスを設定\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "landmark_predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "# PyTorchのデータセット定義\n",
        "class SmileDataset(Dataset):\n",
        "    def __init__(self, image_files):\n",
        "        self.image_files = image_files\n",
        "        self.features, self.labels = self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        features, labels = [], []\n",
        "        for image_file in self.image_files:\n",
        "            img = dlib.load_rgb_image(image_file)\n",
        "            dets = face_detector(img, 1)\n",
        "            for k, d in enumerate(dets):\n",
        "                shape = landmark_predictor(img, d)\n",
        "                lip_points = np.array([[shape.part(i).x, shape.part(i).y] for i in range(48, 68)])\n",
        "                features.append(np.random.rand(10))  # ダミーの特徴量、別途抽出可能\n",
        "                labels.append(lip_points.flatten())\n",
        "        return np.array(features, dtype=np.float32), np.array(labels, dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# ニューラルネットワークのモデル定義\n",
        "class SmileNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SmileNet, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(10, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 40)  # 10ポイントのx,y座標（唇の20個の値）\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# モデルの学習関数\n",
        "def train_model(dataloader, model, epochs=100):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for features, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    # モデルを保存\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(\"モデルを保存しました。\")\n",
        "\n",
        "# モデルの読み込み関数\n",
        "def load_or_train_model(image_files):\n",
        "    model = SmileNet()\n",
        "    if os.path.exists(model_path):\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "        print(\"既存のモデルを読み込みました。\")\n",
        "    else:\n",
        "        dataset = SmileDataset(image_files)\n",
        "        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "        train_model(dataloader, model)\n",
        "    return model\n",
        "\n",
        "# ベジエ曲線で笑顔を描画\n",
        "def generate_smile_image(model):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "\n",
        "    # 予測用のダミー入力\n",
        "    with torch.no_grad():\n",
        "        features = torch.rand(1, 10)\n",
        "        predicted_points = model(features).cpu().numpy().reshape(-1, 2)\n",
        "\n",
        "    # ベジエ曲線描画のための点設定\n",
        "    p1, p2 = predicted_points[0], predicted_points[6]\n",
        "    cp1_upper, cp2_upper = predicted_points[2], predicted_points[4]\n",
        "    cp1_lower, cp2_lower = predicted_points[8], predicted_points[10]\n",
        "\n",
        "    t = np.linspace(0, 1, 100)\n",
        "    upper_x = (1 - t)**3 * p1[0] + 3 * (1 - t)**2 * t * cp1_upper[0] + 3 * (1 - t) * t**2 * cp2_upper[0] + t**3 * p2[0]\n",
        "    upper_y = (1 - t)**3 * p1[1] + 3 * (1 - t)**2 * t * cp1_upper[1] + 3 * (1 - t) * t**2 * cp2_upper[1] + t**3 * p2[1]\n",
        "    lower_x = (1 - t)**3 * p1[0] + 3 * (1 - t)**2 * t * cp1_lower[0] + 3 * (1 - t) * t**2 * cp2_lower[0] + t**3 * p2[0]\n",
        "    lower_y = (1 - t)**3 * p1[1] + 3 * (1 - t)**2 * t * cp1_lower[1] + 3 * (1 - t) * t**2 * cp2_lower[1] + t**3 * p2[1]\n",
        "\n",
        "    plt.plot(upper_x, upper_y, color='black', lw=5)\n",
        "    plt.plot(lower_x, lower_y, color='black', lw=5)\n",
        "    plt.axis('off')\n",
        "\n",
        "    save_directory = '/content/drive/MyDrive/I2T Recognition Dataset/Smiles'\n",
        "    os.makedirs(save_directory, exist_ok=True)\n",
        "    unique_id = uuid.uuid4()\n",
        "    plt.savefig(os.path.join(save_directory, f'smile_{unique_id}.jpg'), bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "# メイン処理\n",
        "image_files = ['/path/to/image1.jpg', '/path/to/image2.jpg']  # 実際の画像ファイルパスに置き換え\n",
        "model = load_or_train_model(image_files)\n",
        "\n",
        "# 画像を生成\n",
        "for _ in range(100):  # 必要な回数を設定\n",
        "    generate_smile_image(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZADw8Kr0Bzor"
      },
      "source": [
        "ピクセル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YazIMQ77B16C"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "input_dir = '/content/drive/MyDrive/Pixel_input_Photo'\n",
        "output_dir = '/content/drive/MyDrive/Pixel_input_Photo/Out_Put_Photo'\n",
        "\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "def process_image(image_path, output_dir, pixel_size=20):\n",
        "\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "\n",
        "    new_width = img.width // pixel_size  # 横方向のピクセル数\n",
        "    new_height = img.height // pixel_size  # 縦方向のピクセル数\n",
        "\n",
        "    # ピクセル化処理\n",
        "    img_small = img.resize((new_width, new_height), Image.NEAREST)\n",
        "    img_pixelated = img_small.resize((img.width, img.height), Image.NEAREST)\n",
        "\n",
        "    # 切り取り範囲を計算\n",
        "    cut_size = pixel_size  # 横方向・縦方向ともに同じサイズ\n",
        "    num_cuts = img.height // cut_size  # 縦方向に切り取れる回数\n",
        "\n",
        "    for i in range(num_cuts):\n",
        "        box = (i * cut_size, 0, (i + 1) * cut_size, img.height)\n",
        "        img_cut = img_pixelated.crop(box)\n",
        "        save_path = os.path.join(output_dir, f\"{os.path.basename(image_path).split('.')[0]}_part{i+1}.png\")\n",
        "        img_cut.save(save_path, format='PNG')\n",
        "for file_name in os.listdir(input_dir):\n",
        "    if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        input_path = os.path.join(input_dir, file_name)\n",
        "        process_image(input_path, output_dir, pixel_size=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5ez7JOH0y1C"
      },
      "source": [
        "ツタから緑を抽出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e3rIzw_06zZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Googleドライブをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 入力と出力のGoogleドライブディレクトリを指定\n",
        "input_dir = \"/content/drive/MyDrive/I2T Recognition Dataset/Plant_Photo\"  # 入力ディレクトリ\n",
        "output_dir = \"/content/drive/MyDrive/I2T Recognition Dataset/Plant_Photo/Plant_Output\"  # 出力ディレクトリ\n",
        "\n",
        "# 緑色範囲の閾値を指定 (例: 適宜調整してください)\n",
        "lower_green = np.array([24, 40, 40])\n",
        "upper_green = np.array([90, 255, 255])\n",
        "\n",
        "# 入力ディレクトリ内のすべての画像ファイルを取得\n",
        "input_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# 出力ディレクトリが存在しない場合は作成\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# すべての画像を処理\n",
        "for file_name in input_files:\n",
        "    input_image_path = os.path.join(input_dir, file_name)\n",
        "    output_image_path = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}_ivy_highlighted.jpg\")\n",
        "\n",
        "    # 画像を読み込む\n",
        "    new_image_cv = cv2.imread(input_image_path)\n",
        "    #\n",
        "    new_image_hsv = cv2.cvtColor(new_image_cv, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # 緑色範囲を検出\n",
        "    new_mask = cv2.inRange(new_image_hsv, lower_green, upper_green)\n",
        "\n",
        "    # 結果画像の作成（背景白、緑部分黒）\n",
        "    new_output = np.full_like(new_image_cv, 255)  # 白背景\n",
        "    new_output[new_mask > 0] = [0, 0, 0]  # 緑部分を黒に設定\n",
        "\n",
        "    # PIL形式に変換して保存\n",
        "    new_output_pil = Image.fromarray(cv2.cvtColor(new_output, cv2.COLOR_BGR2RGB))\n",
        "    new_output_pil.save(output_image_path)\n",
        "\n",
        "    print(f\"処理結果の画像が保存されました: {output_image_path}\")\n",
        "\n",
        "print(\"すべての画像の処理が完了しました。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POOXGP_Uz_yx"
      },
      "source": [
        "画像１枚保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV6PPLva0BgD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from datetime import datetime  # タイムスタンプ用\n",
        "\n",
        "# Googleドライブをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 入力と出力のGoogleドライブディレクトリを指定\n",
        "input_dir = \"/content/drive/MyDrive/Pixel_input_Photo/Out_Put_Photo\"  # 入力ディレクトリ\n",
        "output_dir = \"/content/drive/MyDrive/Pixel_input_Photo\"  # 出力ディレクトリ\n",
        "\n",
        "# 出力ディレクトリが存在しない場合は作成\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 画像を読み込み、すべての画像のリストを作成\n",
        "input_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# 画像をリストに読み込み\n",
        "images = []\n",
        "for file_name in input_files:\n",
        "    image_path = os.path.join(input_dir, file_name)\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is not None:\n",
        "        images.append(img)\n",
        "    else:\n",
        "        print(f\"画像の読み込みに失敗しました: {image_path}\")\n",
        "\n",
        "# 画像が1枚もない場合の処理\n",
        "if not images:\n",
        "    print(\"入力ディレクトリに画像が見つかりませんでした。\")\n",
        "else:\n",
        "    # すべての画像を同じサイズにリサイズ\n",
        "    target_size = (200, 200)  # 画像の幅と高さ（ピクセル単位）\n",
        "    resized_images = [cv2.resize(img, target_size) for img in images]\n",
        "\n",
        "    # グリッドの行数と列数を計算\n",
        "    grid_columns = 31  # グリッドの列数（固定）\n",
        "    grid_rows = (len(resized_images) + grid_columns - 1) // grid_columns  # 必要な行数を計算\n",
        "\n",
        "    # 背景キャンバスを作成\n",
        "    canvas_height = grid_rows * target_size[1]\n",
        "    canvas_width = grid_columns * target_size[0]\n",
        "    canvas = np.full((canvas_height, canvas_width, 3), 255, dtype=np.uint8)  # 白背景\n",
        "\n",
        "    # 画像をキャンバスに配置\n",
        "    for idx, img in enumerate(resized_images):\n",
        "        row = idx // grid_columns\n",
        "        col = idx % grid_columns\n",
        "        y_start = row * target_size[1]\n",
        "        x_start = col * target_size[0]\n",
        "        canvas[y_start:y_start + target_size[1], x_start:x_start + target_size[0]] = img\n",
        "\n",
        "    # 現在のタイムスタンプを取得してファイル名に追加\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_image_path = os.path.join(output_dir, f\"merged_image_{timestamp}.jpg\")\n",
        "\n",
        "    # キャンバスを保存\n",
        "    output_image = Image.fromarray(cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB))\n",
        "    output_image.save(output_image_path)\n",
        "\n",
        "    print(f\"マージした画像が保存されました: {output_image_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ7FjrZ0fr7M"
      },
      "source": [
        "笑顔認識"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTq7xCdDfuVX"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Googleドライブをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 入力ディレクトリと出力ディレクトリを指定\n",
        "input_dir = '/content/drive/MyDrive/I2T Recognition Dataset/Smile_Opart'  # 処理対象の画像があるフォルダ\n",
        "output_dir = '/content/drive/MyDrive/I2T Recognition Dataset/Line_Smile/Face/smile_detection_moredifficult_output'  # 処理結果を保存するフォルダ\n",
        "\n",
        "# 出力ディレクトリが存在しない場合は作成\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Haar Cascade分類器の準備（微笑み検出用）\n",
        "cascade = '/content/drive/MyDrive/I2T Recognition Dataset/Line_Smile/Face/face_output/haarcascade_smile.xml'\n",
        "classifier = cv.CascadeClassifier(cascade)\n",
        "\n",
        "# 入力ディレクトリ内のすべてのファイルを処理\n",
        "for filename in os.listdir(input_dir):\n",
        "    # ファイルパスを作成\n",
        "    file_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    # 画像を読み込む\n",
        "    im = cv.imread(file_path)\n",
        "    if im is None:\n",
        "        print(f\"Skipping {filename}: Not a valid image\")\n",
        "        continue\n",
        "\n",
        "    # グレースケール変換\n",
        "    im_gray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 顔検出（微笑み検出）\n",
        "    faces = classifier.detectMultiScale(\n",
        "    im_gray,\n",
        "    scaleFactor=1.03,  # より厳しいスケール\n",
        "    minNeighbors=50,   # より多くの一致が必要\n",
        "    minSize=(40, 40)   # 特徴サイズを増加\n",
        "    )\n",
        "    # 笑顔領域の後処理\n",
        "    detected_faces = []\n",
        "    for (x, y, w, h) in faces:\n",
        "      if w / h >= 0.8 and w / h <= 1.2:  # 比率チェック\n",
        "        detected_faces.append((x, y, w, h))\n",
        "\n",
        "\n",
        "    # 検出結果を表示\n",
        "    print(f\"Found {len(faces)} face candidates in {filename}\")\n",
        "\n",
        "    # 笑顔が検出された場合のみ画像を保存\n",
        "    if len(faces) > 0:\n",
        "        # 検出された顔を四角で囲む\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv.rectangle(im, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "\n",
        "        # 結果画像を出力ディレクトリに保存\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "        cv.imwrite(output_path, im)\n",
        "        print(f\"Processed image saved to {output_path}\")\n",
        "    else:\n",
        "        print(f\"No faces detected in {filename}, skipping save.\")\n",
        "\n",
        "print(\"All images have been processed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnwItbwYiuDU"
      },
      "source": [
        "顔認識"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNFztS0HivaV"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "import cv2 as cv\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Googleドライブをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 入力ディレクトリと出力ディレクトリを指定\n",
        "input_dir = '/content/drive/MyDrive/I2T Recognition Dataset/Line_Smile/Face'  # 処理対象の画像があるフォルダ\n",
        "output_dir = '/content/drive/MyDrive/I2T Recognition Dataset/Line_Smile/Face/face_output/face'  # 処理結果を保存するフォルダ\n",
        "\n",
        "# 出力ディレクトリが存在しない場合は作成\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Haar Cascade分類器の準備\n",
        "cascade = '/content/drive/MyDrive/I2T Recognition Dataset/Line_Smile/Face/face_output/haarcascade_frontalcatface.xml'\n",
        "classifier = cv.CascadeClassifier(cascade)\n",
        "\n",
        "# パスが正しいか確認\n",
        "if classifier.empty():\n",
        "    print(\"Error: Cascade classifier file not loaded correctly.\")\n",
        "else:\n",
        "    print(\"Cascade classifier loaded successfully.\")\n",
        "\n",
        "# 入力ディレクトリ内のすべてのファイルを処理\n",
        "for filename in os.listdir(input_dir):\n",
        "    # ファイルパスを作成\n",
        "    file_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    # 画像を読み込む\n",
        "    im = cv.imread(file_path)\n",
        "    if im is None:\n",
        "        print(f\"Skipping {filename}: Not a valid image\")\n",
        "        continue\n",
        "\n",
        "    # グレースケール変換\n",
        "    im_gray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 顔検出\n",
        "    faces = classifier.detectMultiScale(\n",
        "        im_gray,\n",
        "        scaleFactor=1.05,\n",
        "        minNeighbors=3,\n",
        "        minSize=(50, 50)\n",
        "    )\n",
        "\n",
        "    # 検出結果を表示\n",
        "    print(f\"Found {len(faces)} face candidates in {filename}\")\n",
        "\n",
        "    # 顔を四角で囲む\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv.rectangle(im, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "\n",
        "    # 結果画像を出力ディレクトリに保存\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    cv.imwrite(output_path, im)\n",
        "\n",
        "    print(f\"Processed image saved to {output_path}\")\n",
        "\n",
        "print(\"All images have been processed.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VHfac2dBLdtG3-XrCPEJF07wdiH4hpvK",
      "authorship_tag": "ABX9TyO6UPuhmkYknf+dcb/lwbsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}